{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad1dd2f",
   "metadata": {},
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb14fd3",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac61b1f",
   "metadata": {},
   "source": [
    "# NLP binary classification app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d353ab1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96501024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3bdcb",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40916456",
   "metadata": {},
   "source": [
    "# Initial preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15665c6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02187d64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fcc38c",
   "metadata": {},
   "source": [
    "**Create a function that loads in data and creates a DataFrame from it. Name it `load_data`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Loads a CSV file and creates a DataFrame from it.\n",
    "\n",
    "    :param data_file: The file you want to load and create a DataFrame from.\n",
    "    :param cols_to_use: Which file columns to use.\n",
    "    :return: DataFrame \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc941594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35db8d98",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b298f",
   "metadata": {},
   "source": [
    "### Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d394c11",
   "metadata": {},
   "source": [
    "**Create a function that handles missing data. Name it `handle_missing_data`. The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that handles missing data by removing rows/columns that contain missing values.\n",
    "\n",
    "    :param data: DataFrame you want to remove missing values from.\n",
    "    :param label: The dependent variable of the data.\n",
    "    :param cut_off_value: The percentage of data a column must be missing to be dropped completely.\n",
    "    :return: Data without missing values.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbe87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7439786a",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78ec7d",
   "metadata": {},
   "source": [
    "### Exercise 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8493b93c",
   "metadata": {},
   "source": [
    "**Create a function that handles duplicates. Name it `handle_duplicates`.**\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that removes duplicates from a given column.\n",
    "    \n",
    "    :param data: DataFrame that contains the data.\n",
    "    :param col_to_process: Column you want to remove duplicates from.\n",
    "    :return: Cleaned data\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d2864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd03c86e",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c639c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99974ec9",
   "metadata": {},
   "source": [
    "**Create a function that one-hot encodes the dependent variable. Name it `one_hot_encode`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that one-hot encodes the label column.\n",
    "    \n",
    "    :param data: The DataFrame that contains the data.\n",
    "    :param label_column: The column to one hot encode.\n",
    "    :return: DataFrame with one hot encoded label column.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f388ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5c1eb8",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1d507",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183dc54",
   "metadata": {},
   "source": [
    "**Create a function that handles data imbalance. Name it `handle_data_imbalance`.**\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that balances data in a DataFrame.\n",
    "\n",
    "    :param data: DataFrame to balance.\n",
    "    :param label: Label column of the DataFrame.\n",
    "    :return: Data with classes that are equally represented.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004dfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af3d9afa",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a66d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c7d08",
   "metadata": {},
   "source": [
    "**Create a function that combines the functions from the previous four exercises into one function that performs initial preprocessing of our data. Name it `initial_preprocessing`. Test the function by creating a cleaned version of the DataFrame you get by loading in the following file: `\"https://edlitera-datasets.s3.amazonaws.com/wine_data_classification.csv\"`. Store the result of the DataFrame cleaning in a new DataFrame. Name that new DataFrame `df_after_initial_preprocessing`.** \n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that performs typical non NLP specific data preprocessing.\n",
    "\n",
    "    :param data: CSV file to create a DataFrame from.\n",
    "    :param cols_to_use: Columns to use from your CSV file.\n",
    "    :param label_column: The column that contains the dependent variable.\n",
    "    :param miss_cut_off: Percentage of data a column must be missing to be removed completely.\n",
    "    :param col_to_process: Column to check for duplicates.\n",
    "    :param handle_imbalance: Whether to handle data imbalance or not.\n",
    "    :return: DataFrame preprocessed with basic non NLP specific techniques.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7870c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0190a1ce",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74346f49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLP specific preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933a837",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf2af3",
   "metadata": {},
   "source": [
    "### Exercise 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec7196",
   "metadata": {},
   "source": [
    "**Create a function that lowercases and tokenizes our text data. Name it `lowercase_and_tokenize`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function look like this:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that lowercases and tokenizes text.\n",
    "    Can tokenize both a Series of strings or a single string.\n",
    "\n",
    "    :param data: Input text data\n",
    "    :param tokenizer: The tokenizer to use\n",
    "    :return: Tokenized version of the text data in the form of a list of strings or a Series of strings.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2952d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975740ea",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a1323",
   "metadata": {},
   "source": [
    "### Exercise 8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967735d",
   "metadata": {},
   "source": [
    "**Create a function that removes stopwords from our text data. Name it `remove_stopwords`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that removes stopwords from some text data.\n",
    "    Can remove stopwords from both a Pandas Series containing lists of strings or a list of strings.\n",
    "\n",
    "    :param data: A Pandas Series or a list of strings\n",
    "    :param stopwords: The list of stopwords to remove from the text data\n",
    "    :return: Text data without stopwords\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbae5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688bb112",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e0ee9",
   "metadata": {},
   "source": [
    "### Exercise 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fa12e",
   "metadata": {},
   "source": [
    "**Create a function that stems our text data. Name it `stemming`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that stems text data.\n",
    "    Can stem both a Pandas Series containing lists of strings or a list of strings.\n",
    "\n",
    "    :param data: Series containing lists of strings or a list of strings.\n",
    "    :param stemmer: The stemmer to use to stem your data.\n",
    "    :param stemmer_language: The language of the stemmer if using the Snowball Stemmer\n",
    "    :return: Stemmed text data.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfb0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c11c9446",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc8d1f",
   "metadata": {},
   "source": [
    "### Exercise 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0077e",
   "metadata": {},
   "source": [
    "**Create a function that converts POS tags from the Treebank format to the Wordnet format. Name it `convert_pos_tags`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Converts POS tags from the Treebank format to the Wordnet format.\n",
    "\n",
    "    :param tag: The tag to convert from one format to another.\n",
    "    :return: POS tag in the Wordnet format.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dda877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e69cdc",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88102d1",
   "metadata": {},
   "source": [
    "### Exercise 11:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13db6b",
   "metadata": {},
   "source": [
    "**Create a function that lemmatizes our text data. Name it `lemmatization`.**\n",
    "\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that lemmatizes text data.\n",
    "    Can lemmatize both a list of strings or a Pandas Series containing lists of strings.\n",
    "\n",
    "    :param data: The text data to lemmatize, either as a list of strings or a Pandas Series containing lists of strings.\n",
    "    :return: Lemmatized text data.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8da627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5ccffa5",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ca2fc",
   "metadata": {},
   "source": [
    "### Exercise 12:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0e38a",
   "metadata": {},
   "source": [
    "**Create a function that combibes the functions from exercises six, seven, eight, nine and ten into one function that performs nlp specific preprocessing of our text data. Name it `nlp_specific_preprocessing`. Test the function by creating a preprocessed version of the DataFrame we created in exercise six. Store the result of the preprocessing in a new DataFrame. Name that new DataFrame `df_after_nlp_preprocessing`.** \n",
    "\n",
    "**The docstrings of the function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that performs NLP specific preprocessing.\n",
    "    Lowercases and tokenizes data.\n",
    "    Removes stopwords.\n",
    "    Performs lemmatization or stemming.\n",
    "\n",
    "    :param data: Input text data, either as a list of strings or a Pandas Series containing lists of strings.\n",
    "    :param col_to_process: The column to preprocess, if preprocessing a column of a DataFrame.\n",
    "    :param new_col_name: Name of a column to add which will contain clean text data.\n",
    "    :param label_column: Column that contains the dependent variable.\n",
    "    :param stop_words: List of stopwords to remove from the text data.\n",
    "    :param tokenizer: The tokenizer to use.\n",
    "    :param stemmer: The stemmer to use (if none provided, lemmatization will be performed)\n",
    "    :return: Preprocessed text data.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db5125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d709f746",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292e0ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prepare data for ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044852fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4bcd9",
   "metadata": {},
   "source": [
    "### Exercise 13:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19abf54",
   "metadata": {},
   "source": [
    "**Create a function that creates a document term matrix that we can use for performing cross validation. Name it `create_document_term_matrix_for_cross_validation`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function look like this:**\n",
    "\n",
    "    \"\"\"\n",
    "    Creates document term matrix you can use to perform cross validation.\n",
    "    \n",
    "    :param data: Text data to create the document term matrix from.\n",
    "    :param label_column: Column that contains the dependent variable.\n",
    "    :param vectorizer: The vectorizer to use to create a document term matrix.\n",
    "    :param max_features: The maximum number of most frequent words to use when creating the document term matrix.\n",
    "    :return: Document term matrix for cross validation\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cfeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a27b43",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b18861",
   "metadata": {},
   "source": [
    "### Exercise 14:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c736b223",
   "metadata": {},
   "source": [
    "**Create a function that creates a document term matrix that we can use for training our model. Name it ` create_document_term_matrix_for_model_training`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Create document term matrix needed to train an ML model.\n",
    "    \n",
    "    :param data: Text data to train the model on.\n",
    "    :param label_column: The column that contains the dependent variable.\n",
    "    :param max_features: The maximum number of most frequent words to use to create a document term matrix.\n",
    "    :param vectorizer: The vectorizer to use to create a document term matrix.\n",
    "    :return: Document term matrix for both training and testing data.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c69af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d476cfe",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c09f4",
   "metadata": {},
   "source": [
    "### Exercise 15:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed55936",
   "metadata": {},
   "source": [
    "**Create a function that creates a document term matrix from some text data, which we can use for making predictions. Name it \n",
    "`create_document_term_matrix_for_making_predictions`.**\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that creates a document term matrix for text data to use in predictions.\n",
    "    \n",
    "    :param data: Text data to create a document term matrix from.\n",
    "    :param vectorizer: The vectorizer to use to create a document term matrix.\n",
    "    :return: Document term matrix.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c5549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2982823d",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4202f5a",
   "metadata": {},
   "source": [
    "### Exercise 16:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e2294",
   "metadata": {},
   "source": [
    "**Use the functions created in exercises thirteen and fourteen to create document term matrices from the DataFrame created in exercise twelve (`df_after_nlp_preprocessing`). Each document term matrix needs to paired with the appropriate label in the form of a Pandas Series. The pairs you need to create are:**\n",
    "\n",
    "* **for cross-validation**: `cross_valid_X, cross_valid_y`\n",
    "* **for training:** `vectorized_train_X, vectorized_test_X, y_train, y_test`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745a999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcdb0c3f",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df705c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ML model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380ea63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b131cc2",
   "metadata": {},
   "source": [
    "### Exercise 17:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d75b3",
   "metadata": {},
   "source": [
    "**Create a function that can perform cross-validation for the following models, on a sample of our total data:**\n",
    "\n",
    "* `Logistic Regression`\n",
    "* `Decision Tree`\n",
    "* `Random Forest`\n",
    "\n",
    "**Name that function `cross_validation_on_sample`. To test the function, use the pair (`cross_valid_X, cross_valid_y`) that you created in exercise sixteen.**\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that tests a number of models using cross validation.\n",
    "\n",
    "    :param document_term_matrix: The document term matrix to use for cross validation.\n",
    "    :param label: The column that contains the dependent variable.\n",
    "    :param models_to_use: The models to try out/perform cross validation for.\n",
    "    :param sample_size: Percentage of total data to use for cross validation.\n",
    "    :param cv: Determines the cross-validation splitting strategy.\n",
    "    :return: List of cross-validation results for different models.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b6516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffc4ffd",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa75565",
   "metadata": {},
   "source": [
    "### Exercise 18:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732a939",
   "metadata": {},
   "source": [
    "**Create a function that can perform cross-validation for the XGBoost model, on a sample of our total data. Name it `cross_validation_xgboost_sample`. To test the function, use the pair (`cross_valid_X, cross_valid_y`) that you created in exercise sixteen.**\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that performs cross validation for the XGBoost model.\n",
    "\n",
    "    :param document_term_matrix: The document term matrix you want to use for cross validation.\n",
    "    :param label: The column that contains the dependent variable.\n",
    "    :param sample_size: Percentage of total data to use for cross validation.\n",
    "    :param num_splits: Number of folds.\n",
    "    :return: Cross-validation results for the XGBoost model.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51b8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb88f445",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4841e33d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59eadbf",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654e28d",
   "metadata": {},
   "source": [
    "### Exercise 19:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e3812",
   "metadata": {},
   "source": [
    "**Create a function that tunes an XGBoost model. Name it `tune_XGBoost_model`. To test the function, use the pair (`cross_valid_X, cross_valid_y`) that you created in exercise sixteen. Use the following parameters for tuning:**\n",
    "    \n",
    "    \n",
    "    random_search_parameters = [\n",
    "      {\n",
    "          'n_estimators': [50, 100, 150, 200],\n",
    "          'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "          'max_depth': range(3, 10),\n",
    "          'colsample_bytree': [0.1, 0.2, 0.3],\n",
    "          'lambda': [1, 5],\n",
    "          'alpha': [0, 1, 5]\n",
    "      }\n",
    "    ]\n",
    "    \n",
    "    grid_search_parameters = [\n",
    "    {\n",
    "        'n_estimators': [100, 150, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    \n",
    "    }   \n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that tunes an XGBoost model either via random search or grid search.\n",
    "\n",
    "    :param document_term_matrix: The document term matrix to use for model tuning.\n",
    "    :param label: The column that contains the dependent variable.\n",
    "    :param search_space: The parameters to try while tuning the model.\n",
    "    :param search_type: Specifies whether to use Random Search or Grid Search.\n",
    "    :param cv: Determines the cross-validation splitting strategy.\n",
    "    :return: Fitted estimator. We can access the best estimator itself or the parameters of the best estimator.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d9df2",
   "metadata": {},
   "source": [
    "**After tuning the models, create a function that saves the tuned models so that they can be used later. Name it `save_tuned_model`.**\n",
    "\n",
    "\n",
    "**The docstrings of that function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that saves a tuned XGBoost model.\n",
    "\n",
    "    :param model: The tuned model to save.\n",
    "    :param model_name: The model name to use.\n",
    "    :return: None\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72a16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c6ff192",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df48e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170f3e7",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5bb05",
   "metadata": {},
   "source": [
    "### Exercise 20:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ff1a8",
   "metadata": {},
   "source": [
    "**Create three helper functions that do the following:**\n",
    "\n",
    "* `train_model` - fits a model on some data\n",
    "* `evaluate_model_accuracy` - function that evaluates the performance of a model on some data.\n",
    "* `save_model` - function that saves a tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e0c3da",
   "metadata": {},
   "source": [
    "**The docstrings of the `train_model` function are:**\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that fits a model on some data.\n",
    "\n",
    "    :param model: The model to fit.\n",
    "    :param X_train: Vectorized version of the independent variable that will be used to train the model.\n",
    "    :param y_train: Dependent variable to predict during training.\n",
    "    :return: Fitted model.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f94d3c",
   "metadata": {},
   "source": [
    "**The docstrings of the `evaluate_model_accuracy` function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that evaluates the performance of a model on some data.\n",
    "\n",
    "    :param model: The model to evaluate.\n",
    "    :param X_test: Vectorized version of the independent variable that will be used to evaluate the model.\n",
    "    :param y_test: Dependent variable to predict during evaluation.\n",
    "    :return: None.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c7ae1",
   "metadata": {},
   "source": [
    "**The docstrings of the `save_model` function are:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that saves a trained model.\n",
    "\n",
    "    :param model: The  model you want to save.\n",
    "    :param model_name: Name under which you want to save the model.\n",
    "    :return: None\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfdb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf3e2ce",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12f25e",
   "metadata": {},
   "source": [
    "### Exercise 21:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080e02e",
   "metadata": {},
   "source": [
    "**Create a function that can train various models and evaluate their performance by combining the functions created in the previous exercise. Name it `train_and_evaluate_model`. Test it out on the data created in exercise 16 (`vectorized_train_X, vectorized_test_X, y_train, y_test`). Try out the following models:**\n",
    "\n",
    "* `Logistic Regression`\n",
    "* `Decision Tree`\n",
    "* `Random Forest`\n",
    "* `Standard XGBoost model`\n",
    "* `Random search tuned XGBoost model`\n",
    "* `Grid search tuned XGBoost model`\n",
    "\n",
    "**The docstrings of that function look like this:**\n",
    "\n",
    "    \"\"\"\n",
    "    Function that fits a given ML model on some data and evaluates the performance of that model.\n",
    "\n",
    "    :param X_train: Vectorized version of the independent variable that will be used to train the model.\n",
    "    :param X_test: Vectorized version of the independent variable that will be used to evaluate the model.\n",
    "    :param y_train: Dependent variable to predict during training.\n",
    "    :param y_test: Dependent variable to predict during evaluation.\n",
    "    :param pre_tune: Defines whether to use a pretuned model or not.\n",
    "    :param model_name: Name of the model to use if not using a pretuned model.\n",
    "    :param pretrained_model: Name of the pretuned model to use.\n",
    "    :return: Fitted model.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc649a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81bc0a9c",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0568b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57313676",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952e3a0",
   "metadata": {},
   "source": [
    "### Exercise 22:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefdd46",
   "metadata": {},
   "source": [
    "**Create two functions that do the following:**\n",
    "\n",
    "* `make_prediction` - makes prediction based on input data\n",
    "* `decode_prediction` - converts the one-hot encoded prediction into the original class\n",
    "\n",
    "**Note: Make sure that the `make_prediction` function preprocesses the input data the same way our training data was preprocessed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed1164",
   "metadata": {},
   "source": [
    "**The docstrings of the `make_prediction` function are:**\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that predicts whether a given review indicates either a good or a superior wine.\n",
    "\n",
    "    :param text: The review to use for prediction.\n",
    "    :param model: The trained model to use when making predictions.\n",
    "    :param vectorizer: The vectorizer used to create the document term matrix we base our prediction on.\n",
    "    :return: Encoded model prediction as an int.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb76f4b",
   "metadata": {},
   "source": [
    "**The docstrings of the `decode_prediction` function are:**\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that converts the one-hot encoded prediction into the original class.\n",
    "\n",
    "    :param initial_data: The original CSV file used for training the model.\n",
    "    :param label: The column that contains the dependent variable.\n",
    "    :param prediction: The prediction made by the model, as an int.\n",
    "    :return: Model prediction as a string.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5bb004",
   "metadata": {},
   "source": [
    "**Make a prediction based on the following input text and decode it:**\n",
    "    \n",
    "    \"The wine is pretty good, but not one of the best I ever tasted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766f748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355247a4",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
