{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b608afb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771fe89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Morphological characteristics`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441cdb6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* study of the internal structure of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a712893",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **`morpheme` -** smallest element with independent meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db02b8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Simple words (word = one morphem):**\n",
    "\n",
    "* run\n",
    "* work\n",
    "* like\n",
    "\n",
    "**Complex words (word = combination of morphemes):**\n",
    "\n",
    "* runner\n",
    "* working\n",
    "* likely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce569f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Processing morphological characteristics:**\n",
    "\n",
    "* `Stemming`\n",
    "* `Lemmatization`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dae2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Stemming`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36a4c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* the process of reducing some word to its root (to its base morpheme)\n",
    "    <br>\n",
    "    \n",
    "    * **runner** --> **run**\n",
    "    <br>\n",
    "    \n",
    "    * **working** --> **work**\n",
    "    <br>\n",
    "    \n",
    "    * **likely** --> **like**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144a1df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we perform **`stemming`** because the ending of some word is usually not important\n",
    "    <br>\n",
    "    \n",
    "    * incidentally, it also makes sure our model will be somewhat robust to spelling errors\n",
    "    * the procedure also involves **converting all strings to lowercase**, so that we don't run into certain problems (such as our model treating the words \"ERROR\" and \"error\" as two different words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987661df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* stemming is preceeded by **`tokenization` (we will talk more about tokenization in a bit)**\n",
    "    <br>\n",
    "    \n",
    "    * for now, think of **`tokenization`** as breaking down some text into words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42a454",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stemming errors**\n",
    "    <br>\n",
    "    <br>\n",
    "* **`over stemming`** - a larger part of some word (more than is needed) is removed\n",
    "    * e.g. reducing words such as universal and university to the same root\n",
    "\n",
    "\n",
    "* **`under stemming`** - multiple words are reduced to more than one root word\n",
    "    * e.g. not reducing alumnus and alumnae to the same root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f28ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* it is very important to pick the right algorithm for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31288ae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Popular stemming algorithms**:\n",
    "     <br>\n",
    "     <br>\n",
    "    \n",
    "   * **`Porter Stemmer`** - efficient, simple, but not the most precise and is also limited to English words\n",
    "    <br>\n",
    "    \n",
    "   * **`Snowball Stemmer (Porter2Stemmer)`** - very popular, more precise over larger datasets than the original Porter Stemmer, not limited to English words\n",
    "    <br>\n",
    "    \n",
    "   * **`Lancaster Stemmer`** - very aggresive, mostly avoided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850c671",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d6338",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* our sentence : ***Life is what happens when you are busy making other plans***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c235d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* stemmed version of our sentence: ***['life', 'is', 'what', 'happen', 'when', 'you', 'are', 'busi', 'make', 'other', 'plan']***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda263c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stemming in `NLTK`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba621a68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we will demonstrate how we perform stemming using the three mentioned stemming algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59347ed2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* for our text, let's use a famous quote from John Lennon\n",
    "\n",
    "    ***Life is what happens when you are busy making other plans***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14e9b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* in **`NLTK`**, stemmers are accessed through the **`nltk.stem`** package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c607d46f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First we need to import the three stemmers from nltk \n",
    "# and define them\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(language='english') # for Snowball Stemmer you need to define the language parameter\n",
    "lancaster_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb6c512",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Then we can create our data\n",
    "# in the form of a list of words\n",
    "\n",
    "text = ['Life', 'is', 'what', 'happens', 'when', 'you', 'are', 'busy', 'making', 'other', 'plans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5881cf3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stemming using Porter Stemmer\n",
    "\n",
    "stemmed_text_porter = []\n",
    "\n",
    "for word in text:\n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    stemmed_text_porter.append(stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38864c94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'is', 'what', 'happen', 'when', 'you', 'are', 'busi', 'make', 'other', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# Stemming result \n",
    "\n",
    "print(stemmed_text_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defe663f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stemming using Snowball Stemmer\n",
    "\n",
    "stemmed_text_snowball = []\n",
    "\n",
    "for word in text:\n",
    "    stemmed_word = snowball_stemmer.stem(word)\n",
    "    stemmed_text_snowball.append(stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2856c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'is', 'what', 'happen', 'when', 'you', 'are', 'busi', 'make', 'other', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# Stemming result \n",
    "\n",
    "print(stemmed_text_snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49af1afe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stemming using Lancaster Stemmer\n",
    "\n",
    "stemmed_text_lancaster = []\n",
    "\n",
    "for word in text:\n",
    "    stemmed_word = lancaster_stemmer.stem(word)\n",
    "    stemmed_text_lancaster.append(stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52f70d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lif', 'is', 'what', 'hap', 'when', 'you', 'ar', 'busy', 'mak', 'oth', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# Stemming result \n",
    "\n",
    "print(stemmed_text_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ebc8019",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'is', 'what', 'happen', 'when', 'you', 'are', 'busi', 'make', 'other', 'plan']\n",
      "['life', 'is', 'what', 'happen', 'when', 'you', 'are', 'busi', 'make', 'other', 'plan']\n",
      "['lif', 'is', 'what', 'hap', 'when', 'you', 'ar', 'busy', 'mak', 'oth', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the results\n",
    "\n",
    "print(stemmed_text_porter)\n",
    "print(stemmed_text_snowball)\n",
    "print(stemmed_text_lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a4f03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f72a56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stem the following words using the Porter2Stemmer (Snowball stemmer):**\n",
    "\n",
    "* university\n",
    "* magnitude\n",
    "* poem\n",
    "* planetary\n",
    "\n",
    "\n",
    "**You can solve the exercise in two ways:**\n",
    "\n",
    "\n",
    "**1.** Stem each word on its own by repeating a few lines of code\n",
    "\n",
    "\n",
    "**2.** Create a list of the words and include the stemming code in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244ea88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2055c7a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['univers', 'magnitud', 'poem', 'planet']\n",
      "['univers', 'magnitud', 'poem', 'planetari']\n",
      "['univers', 'magnitud', 'poem', 'planetari']\n"
     ]
    }
   ],
   "source": [
    "text = ['university','magnitude','poem','planetary']\n",
    "stemmed_text_lancaster = []\n",
    "stemmed_text_snowball = []\n",
    "stemmed_text_porter = []\n",
    "for word in text:\n",
    "    stemmed_word = lancaster_stemmer.stem(word)\n",
    "    stemmed_text_lancaster.append(stemmed_word)\n",
    "    stemmed_word = snowball_stemmer.stem(word)\n",
    "    stemmed_text_snowball.append(stemmed_word)\n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    stemmed_text_porter.append(stemmed_word)\n",
    "    \n",
    "    \n",
    "print(stemmed_text_lancaster)\n",
    "print(stemmed_text_snowball)\n",
    "print(stemmed_text_porter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f979b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc490f9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Use the Porter Stemmer and the Lancaster Stemmer to stem the following string:**\n",
    "\n",
    "`\"That which we call a rose by any other name would smell as sweet\"`\n",
    "\n",
    "\n",
    "**To solve the exercise, convert the string into a list and then create a loop that stems the words in the list.**\n",
    "\n",
    "\n",
    "**Hint:** You can use the **`split()`** method on the string to create a list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af86d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90fa04c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that', 'which', 'we', 'cal', 'a', 'ros', 'by', 'any', 'oth', 'nam', 'would', 'smel', 'as', 'sweet']\n",
      "['that', 'which', 'we', 'call', 'a', 'rose', 'by', 'ani', 'other', 'name', 'would', 'smell', 'as', 'sweet']\n",
      "['that', 'which', 'we', 'call', 'a', 'rose', 'by', 'ani', 'other', 'name', 'would', 'smell', 'as', 'sweet']\n"
     ]
    }
   ],
   "source": [
    "text = \"That which we call a rose by any other name would smell as sweet\"\n",
    "text = text.split(' ')\n",
    "stemmed_text_lancaster = []\n",
    "stemmed_text_snowball = []\n",
    "stemmed_text_porter = []\n",
    "for word in text:\n",
    "    stemmed_word = lancaster_stemmer.stem(word)\n",
    "    stemmed_text_lancaster.append(stemmed_word)\n",
    "    stemmed_word = snowball_stemmer.stem(word)\n",
    "    stemmed_text_snowball.append(stemmed_word)\n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    stemmed_text_porter.append(stemmed_word)\n",
    "print(stemmed_text_lancaster)\n",
    "print(stemmed_text_snowball)\n",
    "print(stemmed_text_porter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81225e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Lemmatizing`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226e2fd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* another popular morphological process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642d7bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* similar to **`stemming`**\n",
    "    <br>\n",
    "    \n",
    "    * also converts a word to its root form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0358459",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Advantages:**\n",
    "    <br>\n",
    "    \n",
    "   * the root form of a word is its **`lemma (dictionary form)`** which makes the result an actual word\n",
    "   <br>\n",
    "   \n",
    "       * e.g. stemming will reduce busy to busi, which is not an actual word\n",
    "       * lemmatization will leave busy as busy\n",
    "    <br>\n",
    "    \n",
    "    \n",
    "   * meaning and context are preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4e068",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Disadvantages:**\n",
    "\n",
    "   * slower (requires a dictionary of lexicons)\n",
    "    <br>\n",
    "    \n",
    "   * very sensitive to spelling errors, so requires preprocessing\n",
    "   \n",
    "   \n",
    "  * libraries such as **`NLTK`** require that we tag each word with a description that says what type of word it is (noun, adjective, verb...)\n",
    " <br>\n",
    " \n",
    " * without supplying **`POS tags`** the results of lemmatization will be worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645209fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some popular lemmatization algorithms can be found in:**\n",
    "    <br>\n",
    "    \n",
    "   * `Wordnet `\n",
    "     <br>\n",
    "    \n",
    "   * `spaCy` \n",
    "     <br>\n",
    "    \n",
    "   * `TextBlob`\n",
    "     <br>\n",
    "    \n",
    "   * `TreeTagger`\n",
    "     <br>\n",
    "    \n",
    "   * `Gensim`\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ff65a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37c411",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* our sentence : ***Life is what happens when you are busy making other plans***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5d6dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* lemmatized version of our sentence: ***['Life', 'be', 'what', 'happen', 'when', 'you', 'be', 'busy', 'make', 'other', 'plan']***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b531f13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lemmatizing in `NLTK`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8f538",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we will demonstrate how we perform **lemmatizing** using the **WordNet algorithm** on the following sentence\n",
    "    <br>\n",
    "    \n",
    "    ***Life is what happens when you are busy making other plans***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7107fc9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **IMPORTANT:** because of how **lemmatization** works, we must import the corpus and perform **POS tagging** *before* **lemmatization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d603f7a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import nltk so that we can use the POS-tagger\n",
    "# Import the lemmatizer and the corpus\n",
    "# Define the lemmatizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bec30c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Then we can create our data\n",
    "# in the form of a list of words\n",
    "\n",
    "text = ['Life', 'is', 'what', 'happens', 'when', 'you', 'are', 'busy', 'making', 'other', 'plans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3358fdb7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's do some POS-tagging\n",
    "\n",
    "tagged_text = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6306c66c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('what', 'WP'),\n",
       " ('happens', 'VBZ'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('busy', 'JJ'),\n",
       " ('making', 'VBG'),\n",
       " ('other', 'JJ'),\n",
       " ('plans', 'NNS')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7734e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Converting tags to `Wordnet` tags**\n",
    "\n",
    "<br>\n",
    "\n",
    "* the automatic **`POS tags`** generated using  **`pos_tag()`**  are generated based on the **`Treebank corpus`**\n",
    "\n",
    "\n",
    "\n",
    "* to perform lemmatization, **`NLTK`** needs **`POS tags`** that the **`Wordnet`** algorithm can use\n",
    "    * **`Wordnet`** is a famous lexical database of nouns, verbs, adjectives and adverbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bec7b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we can create a simple function that will convert our tags\n",
    "    <br>\n",
    "    \n",
    "    * there are 4 **`Wordnet`** tags: **nouns**, **verbs**, **adjectives** and **adverbs**\n",
    "    * to lemmatize using  **`NLTK`** we need to transform all of the tags we get using **`nltk.pos_tag()`** into one of these four groups\n",
    "    * **NOTE:** for tags that are not converted to an equivalent **Wordnet** tag, the lemmatization process will be performed as if we didn't supply any tag at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac263ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = \"this\"\n",
    "tt.startswith('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b69267",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create function that converts tags from treebank to wordnet\n",
    "\n",
    "def convert_pos_tags(tag):\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6570e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaheed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7baab8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get wordnet tagged text\n",
    "\n",
    "wordnet_tagged_text = []\n",
    "\n",
    "for word, tag in tagged_text:\n",
    "    wordnet_tag = convert_pos_tags(tag)\n",
    "    wordnet_tagged_text.append((word,wordnet_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92c2dff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life', 'n'),\n",
       " ('is', 'v'),\n",
       " ('what', None),\n",
       " ('happens', 'v'),\n",
       " ('when', None),\n",
       " ('you', None),\n",
       " ('are', 'v'),\n",
       " ('busy', 'a'),\n",
       " ('making', 'v'),\n",
       " ('other', 'a'),\n",
       " ('plans', 'n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_tagged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf33ebc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **None** isn't problematic: the lemmatizer will treat None as if we didn't supply a POS tag and just lemmatize the word, without the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3f701d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatize using the WordNet algorithm\n",
    "# Snippet of code you can easily reuse later for your own needs\n",
    "\n",
    "lemmatized_text_wordnet = []\n",
    "\n",
    "for word, tag in tagged_text:\n",
    "    wordnet_tag = convert_pos_tags(tag)\n",
    "    if wordnet_tag is None:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word) \n",
    "    else:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, pos=wordnet_tag) \n",
    "    lemmatized_text_wordnet.append(lemmatized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb4cb1f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life', 'be', 'what', 'happen', 'when', 'you', 'be', 'busy', 'make', 'other', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "\n",
    "print(lemmatized_text_wordnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01126a96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**NOTE:**\n",
    "\n",
    "* you can also manually add tags\n",
    "\n",
    "\n",
    "* this is only useful if you want to check one specific word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "679f51a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the lemmatizer to lemmatize the word\n",
    "\n",
    "lemmatizer.lemmatize(\"running\", pos=wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26baec8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fd3be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Lemmatize the following words using the WordNetLemmatizer:**\n",
    "\n",
    "* driving\n",
    "* construction\n",
    "* are\n",
    "* early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4480c2",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22071b53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"driving\",pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b02c1309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'construction'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"construction\",pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ad410a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"are\",pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9f01f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'early'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"early\",pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085dd5d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Morphological Characteristics Cheat Sheet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75b238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02e2d7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* extracting **`morphemes` (smallest elements with independent meaning)** from some text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ef918",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we perform either **`stemming`** or **`lemmatization`**\n",
    "    * performing both is redundant as they essentially try to do the same thing (extract small independent parts of text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aed5a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Stemming`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829d765",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* the process of reducing some word to its root (to its base **`morpheme`**) by using a stemming algorithms\n",
    "    * removes the ending of the word in most cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9427f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* performed because the endings of words are usually not relevant for understanding them\n",
    "    * careful - we must not stem a word too much or too little (**`overstemming`** and **`understemming`**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9cdbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* in **`NLTK`** three algorithms:\n",
    "    <br>\n",
    "    \n",
    "    * **`Porter Stemmer`** - the default option\n",
    "    <br>\n",
    "    \n",
    "    * **`Porter 2 Stemmer (Snowball Stemmer)`** - very precise, but limited in language choice\n",
    "    <br>\n",
    "    \n",
    "    * **`Lancaster Stemmer`** - avoid using it in most cases, stems too much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4160b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Lemmatization`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b7192",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* similar to **`stemming`**, but instead reduces the word to its lemma (dictionary form) which preserves meaning and context "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40807e4b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* requires a dictionary of lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3844c51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* very sensitive to spelling errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501aaed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **`POS tags`** necessary for getting good results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a2a34",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* caution when using **`NLTK`**:\n",
    "    * it uses the **`Wordnet lemmatization algorithm`**, but the built-in tagger produces **`Treebank tags`**\n",
    "    * always convert tags before trying to use them or else **`lemmatization`** won't work as it is supposed to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d25a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
