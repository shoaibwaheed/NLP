{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494a6f9e",
   "metadata": {},
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d604d2",
   "metadata": {},
   "source": [
    "# `Dealing with imbalanced data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53141c7c",
   "metadata": {},
   "source": [
    "* working with imbalanced data usually leads to suboptimal results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c492e5a",
   "metadata": {},
   "source": [
    "* **our models become biased towards classes that are better represented**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02538a14",
   "metadata": {},
   "source": [
    "* the main cause of the accuracy trap\n",
    "    * a situation where accuracy is high, but the model is bad\n",
    "    * in a highly biased dataset the model can start always predicting the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02b67f",
   "metadata": {},
   "source": [
    "* even though tracking how good a model is using the F1 score or something similar allows us to avoid the accuracy trap, it still doesn't solve our problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847cb423",
   "metadata": {},
   "source": [
    "* if you are working with typical imbalanced datasets or text data, there are particular methods you can use to decrease the imbalance as much as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8776a",
   "metadata": {},
   "source": [
    "**Standard solutions to the problem:**\n",
    "\n",
    "* random undersampling \n",
    "* random oversampling\n",
    "* SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884349e2",
   "metadata": {},
   "source": [
    "**NLP specific solutions:**\n",
    "\n",
    "* data augmentation using synonyms\n",
    "* data augmentation using back-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2a8f1",
   "metadata": {},
   "source": [
    "**What you can use in combination with the aforementioned:**\n",
    "\n",
    "* create multiple random samples by undersampling the majority class\n",
    "* afterward train multiple models: each model should train on the whole minority class and one of the random samples you created in the previous step\n",
    "* in the end create an ensemble of models to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e63f6",
   "metadata": {},
   "source": [
    "# `Standard solutions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d13a70",
   "metadata": {},
   "source": [
    "* these methods were not created specifically for working with text data, so they can be applied to any type of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc274dcf",
   "metadata": {},
   "source": [
    "* for random undersampling and oversampling we can use Scikit-Learn, but for SMOTE we will use the `imblearn` library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35617f46",
   "metadata": {},
   "source": [
    "## `Random undersampling`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82094cbd",
   "metadata": {},
   "source": [
    "* **the idea:** if you have more data in one class then in the other, remove examples from the majority class until we have the same number of examples for our two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf25caa",
   "metadata": {},
   "source": [
    "* somewhat wasteful because we end up working with less data than we had in the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3126b",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1020b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first import the libraries we will use\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571d4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "\n",
    "df = pd.read_csv(\"https://edlitera-datasets.s3.amazonaws.com/wine_data_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf87ba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   wine_type\n",
       "0  Aromas include tropical fruit, broom, brimston...  great_wine\n",
       "1  This is ripe and fruity, a wine that is smooth...  great_wine\n",
       "2  Tart and snappy, the flavors of lime flesh and...  great_wine\n",
       "3  Pineapple rind, lemon pith and orange blossom ...  great_wine\n",
       "4  Much like the regular bottling from 2012, this...  great_wine"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first five rows of our dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488e5e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great_wine       96336\n",
       "superior_wine    33635\n",
       "Name: wine_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many examples we have for each class\n",
    "\n",
    "df[\"wine_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0525b46b",
   "metadata": {},
   "source": [
    "We observe that the data is imbalanced: we have far more \"great wines\" as opposed to \"superior wines\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3fd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode data\n",
    "\n",
    "df[\"wine_type\"] = df[\"wine_type\"].map({\"great_wine\": 0, \"superior_wine\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3210a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the two classes\n",
    "\n",
    "great_wine = df[df.wine_type == 0]\n",
    "superior_wine = df[df.wine_type == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6058d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random undersampling to create a sample dataframe of the majority class\n",
    "# that has the same number of examples as the minority class\n",
    "\n",
    "majority_undersampled = resample(\n",
    "    great_wine,\n",
    "    replace=False, # sample without replacement\n",
    "    n_samples=len(superior_wine), # match minority n\n",
    "    random_state=27) # reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb1e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create balanced dataset by combining undersampled majority with minority\n",
    "\n",
    "balanced_df = pd.concat([majority_undersampled, superior_wine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d761e67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33635\n",
       "1    33635\n",
       "Name: wine_type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data balance\n",
    "\n",
    "balanced_df[\"wine_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d64581",
   "metadata": {},
   "source": [
    "## `Random oversampling`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e616a",
   "metadata": {},
   "source": [
    "* **the idea:** if you have more data in one class then in the other, add fake examples to the minority class until we have the same number of examples for our two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd8391",
   "metadata": {},
   "source": [
    "* also called upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed4d46",
   "metadata": {},
   "source": [
    "* the fake examples are duplicates of our real examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6a574",
   "metadata": {},
   "source": [
    "* potentially problematic: increases how much data we have, but depending on the imbalance we can have a lot of duplicates in our dataset which can lead to poor model performance \n",
    "\n",
    "    * especially problematic if duplicate examples end up in both our testing and training data\n",
    "    * **always separate data into training and testing data before oversampling to make sure that duplicates do not artifically increase the performance of your model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73375f4",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665e3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first import the libraries we will use\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ec76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "\n",
    "df = pd.read_csv(\"https://edlitera-datasets.s3.amazonaws.com/wine_data_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08804451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   wine_type\n",
       "0  Aromas include tropical fruit, broom, brimston...  great_wine\n",
       "1  This is ripe and fruity, a wine that is smooth...  great_wine\n",
       "2  Tart and snappy, the flavors of lime flesh and...  great_wine\n",
       "3  Pineapple rind, lemon pith and orange blossom ...  great_wine\n",
       "4  Much like the regular bottling from 2012, this...  great_wine"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first five rows of our dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605c1856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great_wine       96336\n",
       "superior_wine    33635\n",
       "Name: wine_type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many examples we have for each class\n",
    "\n",
    "df[\"wine_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ec3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode data\n",
    "\n",
    "df[\"wine_type\"] = df[\"wine_type\"].map({\"great_wine\": 0, \"superior_wine\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02d404fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's shuffle the dataset now\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f741c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b848a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing data\n",
    "\n",
    "train_data = df.iloc[:85_000, :]\n",
    "valid_data = df.iloc[85_000:100_000, :]\n",
    "test_data = df.iloc[100_000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53b8da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    62892\n",
       "1    22108\n",
       "Name: wine_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check train data for imbalance\n",
    "\n",
    "train_data[\"wine_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f1d1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the two classes\n",
    "\n",
    "great_wine = train_data[train_data.wine_type == 0]\n",
    "superior_wine = train_data[train_data.wine_type == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1bc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random oversampling to create a sample dataframe of the majority class\n",
    "# that has the same number of examples as the minority class\n",
    "\n",
    "\n",
    "minority_upsampled = resample(\n",
    "    superior_wine,\n",
    "    replace=True, # sample with replacement\n",
    "    n_samples=len(great_wine), # match majority n\n",
    "    random_state=27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2568d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create balanced dataset by combining upsampled majority with minority\n",
    "\n",
    "balanced_df = pd.concat([minority_upsampled, great_wine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa72b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    62892\n",
       "0    62892\n",
       "Name: wine_type, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new data \n",
    "\n",
    "balanced_df[\"wine_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83fcdf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new train data\n",
    "\n",
    "train_data = balanced_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beae53c",
   "metadata": {},
   "source": [
    "## `SMOTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ed2b0",
   "metadata": {},
   "source": [
    "* short for **S**YNTHETIC **M**INORITY **O**VERSAMPLING **TE**CHNIQUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86c3be",
   "metadata": {},
   "source": [
    "* type of oversampling where we create fake examples not by creating duplicates of real ones, but by creating synthetic examples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d01ae0",
   "metadata": {},
   "source": [
    "* part of the **`imblearn`** library\n",
    "    * you can install it by running the command **`pip install imblearn`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b946e1",
   "metadata": {},
   "source": [
    "**How are synthetic examples created:**\n",
    "\n",
    "* the algorithm finds a real example in the minority class\n",
    "* it takes a look at its k nearest neighbours\n",
    "* in our feature space, it will create random values that lie somewhere between our real example and its nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a4f2c",
   "metadata": {},
   "source": [
    "**Because of how it works it can be relatively slow (depending on how much data you have) !**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf3080",
   "metadata": {},
   "source": [
    "**Simple example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "665980d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentences': ['i like this',\n",
    "                  'this is terrible',\n",
    "                  'it will not turn out well',\n",
    "                  'i hate this',\n",
    "                  'it has potential'],\n",
    "    'sentiment': [1, 0, 0, 0, 1]})\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['sentences'])\n",
    " \n",
    "sm = SMOTE(k_neighbors=1, random_state=2) \n",
    "\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X, df.sentiment.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f76f934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['this', 'like'], dtype='<U9'),\n",
       " array(['terrible', 'is', 'this'], dtype='<U9'),\n",
       " array(['well', 'out', 'turn', 'not', 'will', 'it'], dtype='<U9'),\n",
       " array(['hate', 'this'], dtype='<U9'),\n",
       " array(['potential', 'has', 'it'], dtype='<U9'),\n",
       " array(['potential', 'has', 'it', 'like', 'this'], dtype='<U9')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sentences after SMOTE\n",
    "\n",
    "vectorizer.inverse_transform(X_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c238f",
   "metadata": {},
   "source": [
    "**There is an extra sentence created by SMOTE !**\n",
    "\n",
    "* let's prove that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc6468b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of original sentences\n",
    "\n",
    "len(df[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5ccef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of sentences in our resampled data\n",
    "\n",
    "X_train_resampled.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2d950",
   "metadata": {},
   "source": [
    "**Complex example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50c8f9",
   "metadata": {},
   "source": [
    "* SMOTE works much better on preprocessed data\n",
    "    * because we are just demonstrating how to create extra examples here we won't go through the whole process of cleaning data, but you should do that when you use SMOTE in practice\n",
    "    * we will do just a little bit of basic data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71005cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first import the libraries we will use\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ff7ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "\n",
    "df = pd.read_csv(\"https://edlitera-datasets.s3.amazonaws.com/wine_data_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c100a4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>great_wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   wine_type\n",
       "0  Aromas include tropical fruit, broom, brimston...  great_wine\n",
       "1  This is ripe and fruity, a wine that is smooth...  great_wine\n",
       "2  Tart and snappy, the flavors of lime flesh and...  great_wine\n",
       "3  Pineapple rind, lemon pith and orange blossom ...  great_wine\n",
       "4  Much like the regular bottling from 2012, this...  great_wine"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first five rows of our dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c16a6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great_wine       96336\n",
       "superior_wine    33635\n",
       "Name: wine_type, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many examples we have for each class\n",
    "\n",
    "df[\"wine_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acfa0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode data\n",
    "\n",
    "df[\"wine_type\"] = df[\"wine_type\"].map({\"great_wine\": 0, \"superior_wine\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53c5900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase text data\n",
    "\n",
    "df[\"description\"]= df[\"description\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c20536e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "words = df[\"description\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b4d7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of stopwords\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "\n",
    "# Remove stopwords\n",
    "\n",
    "words_without_stopwords = words.apply(lambda i: [word for word in i if not word in stopword_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "161b3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stemmer we will use\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(language='english') # for Snowball Stemmer you need to define the language parameter\n",
    "\n",
    "# Perform stemming\n",
    "\n",
    "words_stemmed = words_without_stopwords.apply(lambda i: [snowball_stemmer.stem(word) for word in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90b77f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cleaned data to our original Dataframe\n",
    "\n",
    "df[\"description\"] = words_stemmed.apply(lambda elem: \" \".join(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4ac52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"word\", \n",
    "    token_pattern=r\"\\w+\",\n",
    "    max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c996b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dependent features\n",
    "\n",
    "X = df[\"description\"]\n",
    "\n",
    "# Define independent feature\n",
    "\n",
    "y = df[\"wine_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13828e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training data and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=41)\n",
    "\n",
    "# Separate data into training data and validation data\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.3, \n",
    "    random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a3aba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize data \n",
    "\n",
    "vectorized_train_X = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2978078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63685"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "474d1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SMOTE algorithm\n",
    "\n",
    "smote = SMOTE(random_state=777, k_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1584b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resampled data\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(vectorized_train_X, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71ab7c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94154"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we have increased the size of our train dataset\n",
    "\n",
    "X_train_resampled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7d473f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([47077, 47077], dtype=int64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we have balanced out our labels\n",
    "\n",
    "np.unique(y_train_resampled,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d25c98",
   "metadata": {},
   "source": [
    "# `NLP specific solutions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f5588",
   "metadata": {},
   "source": [
    "* solutions that can be used primarily for text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f041bf",
   "metadata": {},
   "source": [
    "* keep in mind: even if something doesn't make sense to us humans, it doesn't mean models can't use it effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df3b1be",
   "metadata": {},
   "source": [
    "* very advanced methods that don't always lead to better results: depending on the problem you are trying to solve you migh even get worse results than before\n",
    "    <br>\n",
    "    \n",
    "    * main reason: you can easily overfit your data because, even though the examples that are synthetically created are not the same as the original examples, they are still pretty similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d10a8",
   "metadata": {},
   "source": [
    "## `Data augmentation using synonyms`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67f80a",
   "metadata": {},
   "source": [
    "* very simple, yet effective method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e55fd",
   "metadata": {},
   "source": [
    "* a very good library for data augmentation for NLP problems: **`nlpaug`**\n",
    "    * installed with **`pip install nlpaug`**\n",
    "    * requires some other modules such as **`torch`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae7c97",
   "metadata": {},
   "source": [
    "**The procedure:**\n",
    "\n",
    "* take examples of the minority class\n",
    "* for each example, replace some words with their synonyms (by using a very big corpus of words)\n",
    "* somewhat error prone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1494f72",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5494c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7585304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define synonym augmenter\n",
    "# Define what corpus you want to use to find synonyms, and the maximum number of words that get replaced\n",
    "\n",
    "aug = naw.SynonymAug(aug_src='wordnet', aug_max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "890d76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example text\n",
    "\n",
    "text = \"Worst chocolate cake I ever had.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51d2cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment text\n",
    "\n",
    "augmented_text = aug.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dff1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Worst chocolate cake I always had.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show augmented text\n",
    "\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43488cc7",
   "metadata": {},
   "source": [
    "## `Data augmentation using back-translation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba14f89",
   "metadata": {},
   "source": [
    "* a bit more complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7190dc",
   "metadata": {},
   "source": [
    "**The procedure:**\n",
    "\n",
    "* take examples of the minority class\n",
    "* for each example, translate it into a foreign language\n",
    "* after getting a translation, translate that translation back into the original language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557441f",
   "metadata": {},
   "source": [
    "* you can use any translator (even Google translate)\n",
    "    <br>\n",
    "    \n",
    "    * to use the API from Google translate in Python, you need to install the **googletrans** package\n",
    "    * to be more specific, you need to install this version: **pip install googletrans==3.1.0a0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c78dea",
   "metadata": {},
   "source": [
    "**How does the Google translate API work?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb42bb3",
   "metadata": {},
   "source": [
    "* to translate, you use the **`translate()`** function from the **`Translator`** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c097617",
   "metadata": {},
   "source": [
    "* the object that that function returns has the following attributes:\n",
    "    <br>\n",
    "    \n",
    "    * ***src*** - the source language\n",
    "    * ***dest*** - destination language, which is by default set to English (en)\n",
    "    * ***origin*** - original text\n",
    "    * ***text*** - translated text\n",
    "    * ***pronunciation*** - pronunciation of the translated text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7454637",
   "metadata": {},
   "source": [
    "**Example: translate into French and back**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35cfde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the translator from Google translate\n",
    "\n",
    "import googletrans\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ce1a909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
     ]
    }
   ],
   "source": [
    "# Display list of languages to find the abbreviation for French\n",
    "\n",
    "print(googletrans.LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9aa31e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define translator\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30000e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example text\n",
    "\n",
    "original_text = \"Worst chocolate cake I ever had.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86959dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate text into French\n",
    "\n",
    "first_translation = translator.translate(original_text, src=\"en\", dest=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6056fe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le pire g√¢teau au chocolat que j'ai jamais eu.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display translated text\n",
    "\n",
    "first_translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d295004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate text back into English\n",
    "\n",
    "back_translation = translator.translate(first_translation.text, src='fr', dest=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f812a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The worst chocolate cake I've ever had.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text translated back in English\n",
    "\n",
    "back_translation.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95100b",
   "metadata": {},
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
