{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Word representations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Two types of models:**\n",
    "\n",
    "* **co-occurence based models** - train over the whole corpus and capture global dependencies and context\n",
    "\n",
    "* **predictive models** - train over a smaller section (**context window**) and capture local dependencies\n",
    "\n",
    "* we will mostly use predictive models (more on them in the following notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Two types of word representations:**\n",
    "\n",
    "* Sparse representations \n",
    "\n",
    "* Distributed representations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Sparse word representations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Bag-of-words and TFIDF are **sparse representations**\n",
    "    * to represent n different words, we require n dimensions\n",
    "    * in practice: we need as many dimensions as there are words in the dictionary of our entire corpus\n",
    "\n",
    "\n",
    "* this is called the **curse of dimensionality**\n",
    "    * since there are a lot of different words in corpora, when representing n words with n dimensions a lot of the dimensions end up being zeros\n",
    "    \n",
    "    \n",
    "* solution: **limit our vocabulary (limit the number of dimensions of our Vector Space Model)**\n",
    "    * words removed are called **OOV words (Out-Of-Vocabulary words)**\n",
    "    * problem: can't assign semantic meaning to OOV words\n",
    "    \n",
    "    \n",
    "* **additional problem**: hard to find connections between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**We can solve this problem using Word Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Distributed Representations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* for Deep Learning we typically transform words into so-called **word embeddings**\n",
    "    * this allows us to represent words in a neural networks friendly way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* distributed representations are based on the following ideas:\n",
    "    * words used in similar contexts have similar meanings\n",
    "    * meaning can be derived by performing statistical analysis of word usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* great because:\n",
    "    * can create representations for words that are NOT sparse\n",
    "    * can decrease the number of dimensions we need to represent some corpus of words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Vector Space Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* model for representing text data as vectors in some n-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* similar data will be represented with vectors of similar values\n",
    "    * this makes calculating similarities between examples easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"https://edlitera-images.s3.amazonaws.com/vector_space_model.png\" width=\"800\">\n",
    "\n",
    "inspired by:\n",
    "<br>\n",
    "https://www.researchgate.net/publication/298215705_A_Quantitative_Evalution_of_the_Enhanced_Topic-based_Vector_Space_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* vectors that are similar are closer to each other (e.g. the vector \"car\" is close to the vector \"vehicle\", but far from the vector \"wave\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Word embeddings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* instead of representing each word as a one-hot encoded vector we can represent words as combinations of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* can create embeddings for entire documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* drastically decreases the number of values needed to represent a word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* results in dense representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we can also add new words without needing to add new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **IMPORTANT:** because words share the same features, we can easily deduce which words are similar to each other\n",
    "    * example: the vectors representing the words \"boy\" and \"prince\" would be closer to each other than the vectors representing \"girl\" and \"prince\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Word embeddings example`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"https://edlitera-images.s3.amazonaws.com/dense_representation.png\" width=\"700\">\n",
    "\n",
    "source:\n",
    "<br>\n",
    "https://www.r-craft.org/r-news/get-busy-with-word-embeddings-an-introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Concept of analogies`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we can add and substract embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* this works for a lot of different relationships:\n",
    "\n",
    "    * `embedding(smallest) - embedding(small) + embedding(big) ≈ biggest`\n",
    "    * `embedding(Paris) - embedding(France) + embedding(Italy) ≈ Rome`\n",
    "    \n",
    "\n",
    "* very complex relationships are accurately represented using this method\n",
    "* this scales very well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Defining similarity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* proving that two vectors are similar (e.g. Paris - France + Italy ≈ Rome) can be done using various methods:\n",
    "<br>\n",
    "\n",
    "    * using the Euclidean distance between two points\n",
    "        * Pythagora's theorem\n",
    "    * using the cosine similarity \n",
    "        * checks whether the two vectors are pointing in the same direction, the magnitude of the vectors is not important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"https://edlitera-images.s3.amazonaws.com/euclidean_distance_and_cosine_similarity.png\" width=\"700\">\n",
    "\n",
    "source:\n",
    "<br>\n",
    "https://towardsdatascience.com/building-a-backend-system-for-artificial-intelligence-c404efade360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Keras Embedding Layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Keras layer designed for embedding text data \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Can be used in multiple ways:**\n",
    "\n",
    "* Alone - to learn word embeddings which we can save for later and use in other models\n",
    "\n",
    "\n",
    "* Part of a Deep Learning model - embeddings are learned together with everything else\n",
    "\n",
    "\n",
    "* Transfer learning - loading pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ` Layer arguments`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Three important arguments we need to specify:**\n",
    "\n",
    "* input_dim\n",
    "* output_dim\n",
    "* input_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `input_dim`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* directly connected with our integer encoded values\n",
    "    * if we have integer encoded values from 0-20, our vocabulary size would be 21\n",
    "    * this will also be the value we need to use for the **input_dim** argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `output_dim`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* vector space size\n",
    "    * a vector space size of 100 will mean that each word gets encoded as a vector with 100 dimensions\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* there is no \"best value\"\n",
    "    * usually we test out multiple values until we find the best one\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `input_length`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* length of the input sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* works the same as for any other layer\n",
    "    * the total number of words in some document that gets processed in our embedding layer is our **input_length**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Example`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load in data and create DataFrame\n",
    "\n",
    "df = pd.read_csv(\"https://edlitera-datasets.s3.amazonaws.com/customer_complaints_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Take a look at our data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare dataframe sample\n",
    "\n",
    "df = df.iloc[:125000, :]\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Separate dependent feature from the independent feature\n",
    "\n",
    "X = df[\"Consumer_complaint_narrative\"]\n",
    "\n",
    "y = df[\"category_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Take a look at our independent feature\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Take a look at our dependent feature\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Separate data into training data and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Separate data into training data and validation data\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Keras tokenizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* API for preparing text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* a text tokenization class\n",
    "\n",
    "```\n",
    "tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=None,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token=None,\n",
    "    document_count=0, **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Important arguments:**\n",
    "    \n",
    "   * **num_words** - maximum number of words to keep, we define how many most frequent words we want to keep\n",
    "   * **filters** - input to the argument is a string; whatever is in that string will get removed\n",
    "   * **lower** - whether to convert text to lowercase\n",
    "   * **split** - defines how we split words\n",
    "   * **oov_token** - placeholder token for all out-of-vocabulary words used in text_to_sequence calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define tokenizer\n",
    "# Set number of words as 10 000\n",
    "# Set value of oov token\n",
    "# Leave everything else on default values\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=10_000, \n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\nx',\n",
    "    oov_token=\"<OOV>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Keras tokenizer methods:**\n",
    "    \n",
    "   * `fit_on_texts()`\n",
    "   * `texts_to_sequences()`\n",
    "   * `texts_to_matrix()`\n",
    "   * `sequences_to_matrix()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* two important methods we will use are **`fit_on_texts()`** and **`texts_to_sequences()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**`fit_on_texts()`**\n",
    "\n",
    "* we use it to update our vocabulary of texts\n",
    "* the first thing that we use\n",
    "* **only use on training data**\n",
    "\n",
    "* attributes:\n",
    "    * word_counts - gives use all of the words inside the dictionary together with their counts\n",
    "    * word_docs - gives use all of the words inside the dictionary together with information on the number of documents that word appeared in\n",
    "    * word_index - unique integers, we assign one to each word\n",
    "    * document_count - total number of documents that we used to fit the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Fit tokenizer on train data\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**texts_to_sequences()**\n",
    "\n",
    "* converts tokens of some corpus into sequences of integers\n",
    "* used after fit_on_texts(), but before padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convert into sequences of integers\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_valid = tokenizer.texts_to_sequences(X_valid)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* when using the keras embedding layer, (actually any neural network layer), we always must input data of the same dimensions\n",
    "\n",
    "* **problem:** sentences are often of different length\n",
    "\n",
    "* **solution:** select a max length for the sentences and make sure that all sentences are of that length\n",
    "    * if a sentence is longer, truncate it \n",
    "    * if a sentence is shorter, pad it with zeroes\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* always pad all data (training, validation and testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_len_of_sequence = max(len(x) for x in X_train)\n",
    "\n",
    "print(max_len_of_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define values important for padding\n",
    "\n",
    "max_length = 100\n",
    "trunc_type = \"post\"\n",
    "padding_type = \"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Pad train, validation and test data\n",
    "\n",
    "X_train = pad_sequences(X_train, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
    "X_valid = pad_sequences(X_valid, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
    "X_test = pad_sequences(X_test, padding=padding_type, maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* don't worry about this part: we'll cover it in detail in just a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* for now, you only need to understand the embedding layer:\n",
    "    \n",
    "    * as the **input_dim** argument use the size of your vocabulary + 1\n",
    "    * as the **output_dim** use how many vectors do you want to use to embed your words\n",
    "    * as **max_length** use the number of words you limited your sentences to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "embedding_dim = 100\n",
    "input_dim = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=input_dim, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(LSTM(32, recurrent_dropout=0.2)) \n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(y.nunique(), activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model compiling and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "loss_function = SparseCategoricalCrossentropy()\n",
    "\n",
    "metric = SparseCategoricalAccuracy()\n",
    "\n",
    "optim = Adam()\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optim, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Problem we typically run into: not enough data !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Solution: use pretrained word vectors**\n",
    "\n",
    "* we use pretrained vectors from:\n",
    "\n",
    "    * `spaCy`\n",
    "    * `Word2Vec`\n",
    "    * `GloVe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* using pretrained components in our model is the basis of **transfer learning**\n",
    "    * more on transfer learning later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <div>\n",
    "<img src=\"https://edlitera-images.s3.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
